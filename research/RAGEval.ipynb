{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating RAG Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings \n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms.openai import OpenAI as LangchainOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class MedicAI:\n",
    "    def __init__(self, data_path):\n",
    "        \"\"\"\n",
    "        Just Pass Data Path to the Class and it will handle the rest\n",
    "        \"\"\"\n",
    "        def load_pdf(data):\n",
    "            loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls = PyPDFLoader)\n",
    "            docs = loader.load()\n",
    "            return docs\n",
    "        self.data_path = data_path\n",
    "        self.extracted_data = load_pdf(data=self.data_path)\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # def create_embeddings(self):\n",
    "    #     return self.embeddings.embed_query(\"hey there\")\n",
    "    def setup_pinecone(self, api_key, index_name = \"tanishka\"):\n",
    "        pc = Pinecone(api_key=api_key)\n",
    "        return pc \n",
    "\n",
    "    def create_pinecone_index(self, api_key, index_name = \"tanishka\"):\n",
    "        pc = Pinecone(api_key = api_key)\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension= 384, \n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            ) \n",
    "        )\n",
    "        return pc \n",
    "    \n",
    "    def get_docsearch_from_pinecone(self, index_name, embeddings):\n",
    "        docsearch = PineconeVectorStore.from_existing_index(\n",
    "            index_name=index_name,\n",
    "            embedding=embeddings\n",
    "        )\n",
    "        return docsearch\n",
    "    \n",
    "    def setup_local_gemma(self):\n",
    "        client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "        llm = LangchainOpenAI(\n",
    "        openai_api_key=\"lm-studio\",\n",
    "        openai_api_base=\"http://localhost:1234/v1\",\n",
    "        model_name=\"gemma-2-2b-instruct\",\n",
    "        temperature=0.7\n",
    "        )\n",
    "        return client, llm \n",
    "    \n",
    "    def setup_rag_chain(self,llm,vectorstore):\n",
    "        template = \"\"\"\n",
    "        You are Dr. Medic, A medical expert and an assistant for question-answering tasks.\n",
    "        You are given a question and you need to answer it based on the retrieved context.\n",
    "        If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "        You need to answer mostly in plain text, you may use bold text, bullets if necessary, do not use ``` tags at any cost.\n",
    "        Do not talk about the text or context, just answer.\n",
    "        Do not state the context provided to you to the user, keep it a secret and just answer. If you dont have any information related to the question, just say you don't know.\n",
    "        Answer in atleast 100 words, you may add your creativity without messing the originality.\n",
    "        \n",
    "\n",
    "        Context: {context}\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "        def format_docs(docs):\n",
    "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        rag_chain = (\n",
    "            {\n",
    "                \"context\": retriever | format_docs,\n",
    "                \"question\": RunnablePassthrough()\n",
    "            }\n",
    "            | rag_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        return rag_chain\n",
    "    \n",
    "    def enter_qa(self, rag_chain):\n",
    "        while True:\n",
    "            try:\n",
    "                print(\"About to invoke the rag_chain\")\n",
    "                question = input(\"Enter your prompt (type 'exit' to exit the loop): \")\n",
    "                if question.lower() == \"exit\":\n",
    "                    break\n",
    "                for chunk in rag_chain.stream(question):\n",
    "                    print(chunk, end=\"\", flush=True)\n",
    "                print(\"\\nJust finished invoking the rag_chain\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pinecone.grpc.pinecone.PineconeGRPC'>\n"
     ]
    }
   ],
   "source": [
    "medic_ai = MedicAI('..//Data/')\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc = medic_ai.setup_pinecone(api_key=api_key)\n",
    "print(type(pc))\n",
    "vectorstore = medic_ai.get_docsearch_from_pinecone(index_name=\"tanishka\", embeddings=medic_ai.embeddings)\n",
    "llm = medic_ai.setup_local_gemma()\n",
    "rag_chain = medic_ai.setup_rag_chain(llm=llm[1], vectorstore=vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Resources\\nBOOKS\\n“Acute Pulmonary Edema.” In Current Medical Diagnosis and\\nTreatment, 1998. 37th ed. Ed. Stephen McPhee, et al.\\nStamford: Appleton & Lange, 1997.\\nDeBakey, Michael E., and Antonio M. Gotto Jr. The New Living\\nHeart. Holbrook, MA: Adams Media Corporation, 1997.KEY TERMS\\nEdema —Swelling caused by accumulation of fluid\\nin body tissues.\\nIschemia —A condition in which the heart muscle\\nreceives an insufficient supply of blood and slowlystarves.\\nLeft ventricle —The large chamber on the lower\\nleft side of the heart. The left ventricle sends bloodto the lungs and the rest of the body.\\nMitral stenosis —Narrowing or constricting of the', 'Resources\\nBOOKS\\n“Acute Pulmonary Edema.” In Current Medical Diagnosis and\\nTreatment, 1998. 37th ed. Ed. Stephen McPhee, et al.\\nStamford: Appleton & Lange, 1997.\\nDeBakey, Michael E., and Antonio M. Gotto Jr. The New Living\\nHeart. Holbrook, MA: Adams Media Corporation, 1997.KEY TERMS\\nEdema —Swelling caused by accumulation of fluid\\nin body tissues.\\nIschemia —A condition in which the heart muscle\\nreceives an insufficient supply of blood and slowlystarves.\\nLeft ventricle —The large chamber on the lower\\nleft side of the heart. The left ventricle sends bloodto the lungs and the rest of the body.\\nMitral stenosis —Narrowing or constricting of the', 'Resources\\nBOOKS\\n“Acute Pulmonary Edema.” In Current Medical Diagnosis and\\nTreatment, 1998. 37th ed. Ed. Stephen McPhee, et al.\\nStamford: Appleton & Lange, 1997.\\nDeBakey, Michael E., and Antonio M. Gotto Jr. The New Living\\nHeart. Holbrook, MA: Adams Media Corporation, 1997.KEY TERMS\\nEdema —Swelling caused by accumulation of fluid\\nin body tissues.\\nIschemia —A condition in which the heart muscle\\nreceives an insufficient supply of blood and slowlystarves.\\nLeft ventricle —The large chamber on the lower\\nleft side of the heart. The left ventricle sends bloodto the lungs and the rest of the body.\\nMitral stenosis —Narrowing or constricting of the', 'Resources\\nBOOKS\\n“Acute Pulmonary Edema.” In Current Medical Diagnosis and\\nTreatment, 1998. 37th ed. Ed. Stephen McPhee, et al.\\nStamford: Appleton & Lange, 1997.\\nDeBakey, Michael E., and Antonio M. Gotto Jr. The New Living\\nHeart. Holbrook, MA: Adams Media Corporation, 1997.KEY TERMS\\nEdema —Swelling caused by accumulation of fluid\\nin body tissues.\\nIschemia —A condition in which the heart muscle\\nreceives an insufficient supply of blood and slowlystarves.\\nLeft ventricle —The large chamber on the lower\\nleft side of the heart. The left ventricle sends bloodto the lungs and the rest of the body.\\nMitral stenosis —Narrowing or constricting of the']\n"
     ]
    }
   ],
   "source": [
    "retreived_docs = vectorstore.similarity_search(\"What is Edema ?\")\n",
    "contexts = [doc.page_content for doc in retreived_docs]\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
      "    num_rows: 3\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\"What is Edema?\", \n",
    "             \"What is Cardiac Arrest?\",\n",
    "             \"What is Pancreatic Cancer?\",\n",
    "            ]\n",
    "ground_truths = [[\"Edema is swelling caused by too much fluid trapped in the body's tissues.\"],\n",
    "                [\"A cardiac arrest, also known as sudden cardiac arrest, is a medical emergency that occurs when the heart suddenly stops beating.\"],\n",
    "                [\"Pancreatic cancer is a type of cancer that occurs when malignant cells develop in the pancreas. It can affect the pancreas's functioning, including the endocrine or exocrine glands. \"]]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# Inference\n",
    "for query in questions:\n",
    "  answers.append(rag_chain.invoke(query))\n",
    "  contexts.append([docs.page_content for docs in vectorstore.similarity_search(query)])\n",
    "\n",
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32df8a93a114c3da6cb10123dfcdaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
